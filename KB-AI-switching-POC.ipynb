{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d57f80-9d27-4dbc-8676-df032d19be5a",
   "metadata": {},
   "source": [
    "# Switching Assistant\n",
    "- Intent classification and Service Routing\n",
    "- The LLM analyzes this combination and classifies the input into one or combination of three main intents: AppAssistant, PainAssistant, or PersonalAssistant.\n",
    "- Creating through bedrock-agent for more confirugation and control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c2331d-b7d1-44e9-bd96-e19b7602de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running boto3 version: 1.35.34\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError, ClientError\n",
    "import os\n",
    "import random\n",
    "from retrying import retry\n",
    "import time\n",
    "from utility import *\n",
    "print('Running boto3 version:', boto3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e9f01-aada-46eb-9667-f8323098a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock Agent runtime\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "session = boto3.session.Session()\n",
    "region = 'ca-central-1'\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\", config=bedrock_config, region_name = region)\n",
    "\n",
    "# KB ID\n",
    "kb_id = 'V2W0LT3GZP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9544e97-e1f6-482f-8614-ffd7cf401000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, kbId, numberOfResults=5):\n",
    "    return bedrock_agent_client.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\", # optional\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['content']['text'])\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a428ae-3dce-4392-844f-738de7f9501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the default knowledge base prompt\n",
    "\n",
    "path = '../machine-learning/4. Knowledge Base Template/'\n",
    "filename = 'Switching_Assistant_V1_Oct17.md'\n",
    "\n",
    "with open(path+filename, 'r') as f:\n",
    "    prompt_template = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691291e8-23de-40a3-822b-c06693f4903b",
   "metadata": {},
   "source": [
    "Evaluating role switching on Potential Questions 2 (which is supposed to be only for app assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b4b9b-8e92-49fa-925a-4a436b1f7321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the questions that we want to ask\n",
    "\n",
    "path = '../machine-learning/6. Test Cases/App Assistant/'\n",
    "filename = 'Potential-Questions2.md'\n",
    "\n",
    "with open(path+filename, 'r') as f:\n",
    "    questions = f.read()\n",
    "\n",
    "queries = questions.split('\\n')\n",
    "\n",
    "\n",
    "# Going through the queries to send to LLM\n",
    "\n",
    "for query in queries:\n",
    "    print ('---------------------------------------------------- \\n')\n",
    "\n",
    "    # Acquire the context\n",
    "    response = retrieve(query, kb_id)\n",
    "    retrievalResults = response['retrievalResults']\n",
    "    contexts = get_contexts(retrievalResults)\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = f\"\"\"\n",
    "    Human: Use the following <context> to determine if the intent of <query> is classified as AI App assistant or as the \n",
    "    Pain assistant as decribed in <prompt_template>\n",
    "    \n",
    "    <prompt_template>\n",
    "    {prompt_template}\n",
    "    </prompt_template>\n",
    "    \n",
    "    <context>\n",
    "    {contexts}\n",
    "    </context>\n",
    "    \n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    Only respond with the title name of the assistant chosen.\n",
    "    Do not respond if the prompt is not related to <contexts>.\n",
    "    \n",
    "    Assistant:\"\"\"\n",
    "\n",
    "    # Prepare the information to be invoked into the model\n",
    "    messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt.format(prompt_template, contexts, query)}]}]\n",
    "    sonnet_payload = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1\n",
    "            }  )\n",
    "    modelId = 'anthropic.claude-3-sonnet-20240229-v1:0' \n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    response = bedrock_client.invoke_model(body=sonnet_payload, \n",
    "                                           modelId=modelId, \n",
    "                                           accept=accept, \n",
    "                                           contentType=contentType)\n",
    "\n",
    "    # Call and print the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text = response_body.get('content')[0]['text']\n",
    "    # pp.pprint (query)\n",
    "    # pp.pprint(response_text)\n",
    "    print (query)\n",
    "    print (response_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a6ce1-fa2a-4f1d-9927-45e107a9a3dc",
   "metadata": {},
   "source": [
    "--- \n",
    "# Test the role switching from app assistant to pain pscyhology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc807000-703d-42b8-b02a-c1bafe79b8d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the questions that we want to ask\n",
    "\n",
    "path = '../machine-learning/6. Test Cases/'\n",
    "filename = 'Role-Switching2.md'\n",
    "\n",
    "with open(path+filename, 'r') as f:\n",
    "    questions = f.read()\n",
    "\n",
    "queries = questions.split('\\n')\n",
    "\n",
    "\n",
    "# Going through the queries to send to LLM\n",
    "\n",
    "for query in queries:\n",
    "    print ('---------------------------------------------------- \\n')\n",
    "\n",
    "    # Acquire the context\n",
    "    response = retrieve(query, kb_id)\n",
    "    retrievalResults = response['retrievalResults']\n",
    "    contexts = get_contexts(retrievalResults)\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = f\"\"\"\n",
    "    Human: Use the following <context> to determine if the intent of <query> is classified as AI App assistant or as the \n",
    "    Pain assistant as decribed in <prompt_template>. \n",
    "    \n",
    "    <prompt_template>\n",
    "    {prompt_template}\n",
    "    </prompt_template>\n",
    "    \n",
    "    <context>\n",
    "    {contexts}\n",
    "    </context>\n",
    "    \n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    Only respond with the title name of the assistant(s) chosen. \n",
    "    Do not respond if the prompt is not related to <contexts>.\n",
    "    \n",
    "    Assistant:\"\"\"\n",
    "\n",
    "    # Prepare the information to be invoked into the model\n",
    "    messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt.format(prompt_template, contexts, query)}]}]\n",
    "    sonnet_payload = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1\n",
    "            }  )\n",
    "    modelId = 'anthropic.claude-3-sonnet-20240229-v1:0' \n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    response = bedrock_client.invoke_model(body=sonnet_payload, \n",
    "                                           modelId=modelId, \n",
    "                                           accept=accept, \n",
    "                                           contentType=contentType)\n",
    "\n",
    "    # Call and print the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text = response_body.get('content')[0]['text']\n",
    "    # pp.pprint (query)\n",
    "    # pp.pprint(response_text)\n",
    "    print (query)\n",
    "    print (response_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aef34e-06b6-4ae3-86c4-a86efc414bfd",
   "metadata": {},
   "source": [
    "--- \n",
    "# Role switching extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84ce3ec7-700b-404a-a55d-81731790609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock Agent runtime\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "session = boto3.session.Session()\n",
    "region = 'ca-central-1'\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\", config=bedrock_config, region_name = region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8d853e8-7785-4c6e-b5f7-b2f0c05e1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, kbId, numberOfResults=5):\n",
    "    return bedrock_agent_client.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\", # optional\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['content']['text'])\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c015d221-6812-458b-a6fc-8233e06039aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_choice (prompt_template1, query, contexts, choice, prompt_template2 = None):\n",
    "\n",
    "        if (choice == 'Intent'):\n",
    "            prompt = f\"\"\"\n",
    "            Human: Use the following <context> to determine if the intent of <query> is classified as AI App assistant or as the \n",
    "            Pain assistant as decribed in <prompt_template1>. \n",
    "\n",
    "            If the intent is classified as AI App assistant then respond with 'AI Assistant for the App', \n",
    "            if the intent is classified as the Pain assistant then respond with 'Pain Psychologist',\n",
    "            if the intent is classifed as both the AI App assistant and Pain assistant then respond with 'AI Assistant for the App, Pain Psychologist'\n",
    "            \n",
    "            <prompt_template1>\n",
    "            {prompt_template1}\n",
    "            </prompt_template1>\n",
    "            \n",
    "            <context>\n",
    "            {contexts}\n",
    "            </context>\n",
    "            \n",
    "            <query>\n",
    "            {query}\n",
    "            </query>\n",
    "        \n",
    "            Only respond with the title name of the assistant(s) chosen. \n",
    "            Do not respond if the prompt is not related to <contexts>.\n",
    "            \n",
    "            Assistant:\"\"\"\n",
    "            \n",
    "        elif (choice == 'Pain'):\n",
    "            prompt = f\"\"\"\n",
    "            Human: Use the following <context> to answer the <query> according to your role in <prompt_template1>. \n",
    "            <prompt_template1>\n",
    "            {prompt_template1}\n",
    "            </prompt_template1>\n",
    "            \n",
    "            <context>\n",
    "            {contexts}\n",
    "            </context>\n",
    "            \n",
    "            <query>\n",
    "            {query}\n",
    "            </query>\n",
    "            \n",
    "            Do not respond if the prompt is not related to pain Psychology.\n",
    "            Do not respond if the prompt is not related to <contexts>.\n",
    "            Do not respond if the prompt is related to usage of the app.\n",
    "            \n",
    "            Assistant:\"\"\"\n",
    "\n",
    "\n",
    "        elif (choice == 'App'):\n",
    "            prompt = f\"\"\"\n",
    "            Human: Use the following <context> to answer the <query> according to your role in <prompt_template1>. \n",
    "            <prompt_template1>\n",
    "            {prompt_template1}\n",
    "            </prompt_template1>\n",
    "            \n",
    "            <context>\n",
    "            {contexts}\n",
    "            </context>\n",
    "            \n",
    "            <query>\n",
    "            {query}\n",
    "            </query>\n",
    "            \n",
    "            Do not respond if the prompt is not related to the app.\n",
    "            \n",
    "            Assistant:\"\"\"\n",
    "\n",
    "        elif (choice == 'Both'):\n",
    "            prompt = f\"\"\"\n",
    "            Human: Your role is <prompt_template1> and <prompt_template2>. Please combine the texts in <query> to make it a consistent \n",
    "            and remove any iterations. Be concise when responding.\n",
    "            \n",
    "            \n",
    "            <prompt_template1>\n",
    "            {prompt_template1}\n",
    "            </prompt_template1>\n",
    "            \n",
    "            <prompt_template2>\n",
    "            {prompt_template2}\n",
    "            </prompt_template2>\n",
    "            \n",
    "            <query>\n",
    "            {query}\n",
    "            </query>\n",
    "            \n",
    "            Assistant:\"\"\"\n",
    "\n",
    "\n",
    "        return (prompt)\n",
    "\n",
    "\n",
    "def prompt_template_choice(choice):\n",
    "    # Assigning the default knowledge base prompt\n",
    "    path = '../machine-learning/4. Knowledge Base Template/'\n",
    "\n",
    "    if (choice == 'Intent'):\n",
    "        filename = 'Switching_Assistant_V1_Oct17.md'\n",
    "\n",
    "    elif (choice == 'Pain'):\n",
    "        filename = 'Pain_Assistant_V1_Oct15.md'\n",
    "            \n",
    "    elif (choice == 'App'):\n",
    "        filename = 'App_Assistant_V1_Oct10.md'\n",
    "        \n",
    "    with open(path+filename, 'r') as f:\n",
    "        prompt_template = f.read()\n",
    "            \n",
    "    return (prompt_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d77221ca-1cd8-4554-93d5-b670c228466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_ingestion (prompt, prompt_template, contexts, query, temp = 1):\n",
    "\n",
    "    # Prepare the information to be invoked into the model\n",
    "    messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt.format(prompt_template, contexts, query)}]}]\n",
    "    sonnet_payload = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"messages\": messages,\n",
    "    \"temperature\": temp,\n",
    "    \"top_p\": 1\n",
    "        }  )\n",
    "    modelId = 'anthropic.claude-3-sonnet-20240229-v1:0' \n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    response = bedrock_client.invoke_model(body=sonnet_payload, \n",
    "                                       modelId=modelId, \n",
    "                                       accept=accept, \n",
    "                                       contentType=contentType)\n",
    "    \n",
    "    return (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e779fed1-520f-4c75-84b7-32cb31ec1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge base ID\n",
    "\n",
    "kb_aws_bedorck_s3 = '76UIT87ACB'\n",
    "kb_app_assistant = 'V2W0LT3GZP'\n",
    "kb_pain_assistant = 'KESDTCXEJE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d30a6fa3-2c28-4004-81f2-bc0cd3fcd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \n",
      "Begin LLM for Intent Classification\n",
      "---------------------------------------------------- \n",
      "\n",
      "How do I update my pain condition in the app? How does stress or anxiety affect my pain levels?\n",
      "AI Assistant for the App, Pain Psychologist\n",
      "\n",
      "---------------------------------------------------- \n",
      "End of intent classification\n",
      "---------------------------------------------------- \n",
      "Begin LLM for App AI Assistant\n",
      "---------------------------------------------------- \n",
      "\n",
      "I can provide instructions on how to update your pain conditions in the Manage My Pain app, but I cannot advise on how stress or anxiety affects pain levels, as that would be providing medical advice which is outside of my capabilities.\n",
      "\n",
      "To update your pain conditions in the app:\n",
      "\n",
      "1. Open the app and go to the \"Settings\" section.\n",
      "2. Look for the \"Pain Conditions\" or \"My Conditions\" option.\n",
      "3. Tap on the condition you want to update or edit.\n",
      "4. Make the necessary changes like updating the name, symptoms, triggers, etc.\n",
      "5. Save the changes when done.\n",
      "\n",
      "The app allows you to customize and track the details of your specific pain conditions. This can help provide a better overview to share with your doctor.\n",
      "\n",
      "Do you need any other assistance regarding using the app's features? I'd be happy to provide more instructions. Let me know if you want to learn more.\n",
      "\n",
      " ---------------------------------------------------- \n",
      "End of App AI Assistant\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \n",
      "Begin LLM for Pain Assistant\n",
      "---------------------------------------------------- \n",
      "\n",
      "As an expert in pain psychology, I cannot provide specific instructions on using the app, but I can offer guidance on how stress and anxiety can impact pain levels.\n",
      "\n",
      "Chronic pain and emotional states like stress and anxiety are closely interlinked. High levels of stress and anxiety can amplify pain perception and make it more difficult to cope with chronic pain. This is because stress triggers physiological responses like muscle tension, increased inflammation, and disrupted sleep, all of which can exacerbate pain. \n",
      "\n",
      "Additionally, anxiety about pain can lead to fear-avoidance behaviors, where individuals avoid activities they believe will worsen their pain, ultimately leading to deconditioning and more pain. It's important to manage stress through relaxation techniques, cognitive-behavioral strategies, and addressing underlying psychological factors.\n",
      "\n",
      "Focusing on stress management, practicing mindfulness, and seeking support can help break the cycle of stress, anxiety, and heightened pain perception. Would you like me to suggest some specific coping strategies to manage the impact of stress and anxiety on your pain experience?\n",
      "\n",
      "----------------------------------------------------\n",
      "End of Pain AI Assistant\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \n",
      "Begin LLM for Pain and App Assistant\n",
      "---------------------------------------------------- \n",
      "\n",
      "To update your pain condition in the app, go to the \"Profile\" section and select \"Edit Pain Conditions\". From there, you can add, remove, or modify the details of your pain conditions.\n",
      "\n",
      "Regarding your second question, stress and anxiety can often exacerbate pain levels. Chronic pain is both a physical and psychological experience, and high stress or anxiety levels can intensify the perception of pain. Managing stress through relaxation techniques, mindfulness, or therapy may help reduce pain levels.\n",
      "\n",
      "Do you want to learn more about tracking your pain, stress, and anxiety levels within the app? I'd be happy to provide additional guidance.\n",
      "\n",
      "----------------------------------------------------\n",
      "End of Pain and App AI Assistant\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \n"
     ]
    }
   ],
   "source": [
    "############ Loading the questions that we want to ask\n",
    "\n",
    "path = '../machine-learning/6. Test Cases/'\n",
    "filename = 'Role-Switching2.md'\n",
    "\n",
    "with open(path+filename, 'r') as f:\n",
    "    questions = f.read()\n",
    "\n",
    "queries = questions.split('\\n')\n",
    "query = queries [0]\n",
    "\n",
    "############ Main body of the analysis\n",
    "\n",
    "print ('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx ')\n",
    "print ('Begin LLM for Intent Classification')\n",
    "print ('---------------------------------------------------- \\n')\n",
    "\n",
    "# Acquire the context\n",
    "response = retrieve(query, kb_aws_bedorck_s3)\n",
    "retrievalResults = response['retrievalResults']\n",
    "contexts = get_contexts(retrievalResults)\n",
    "\n",
    "# Choose the prompt template\n",
    "prompt_template_intent = prompt_template_choice('Intent')\n",
    "\n",
    "# Format the Prompt with the prompt template\n",
    "prompt_role_intent = prompt_choice (prompt_template_intent, query, contexts, 'Intent')\n",
    "\n",
    "# Ingest data into the LLM (Modifications can be applied here)\n",
    "response = data_ingestion (prompt_role_intent, prompt_template_intent, contexts, query, 0)\n",
    "\n",
    "# Call and print the response\n",
    "response_body = json.loads(response.get('body').read())\n",
    "response_text_intent = response_body.get('content')[0]['text']\n",
    "print (query)\n",
    "print (response_text_intent)\n",
    "\n",
    "print ('\\n---------------------------------------------------- ')\n",
    "print ('End of intent classification')\n",
    "print ('---------------------------------------------------- ')\n",
    "\n",
    "if ((response_text_intent == 'AI Assistant for the App') or (response_text_intent == 'AI Assistant for the App, Pain Psychologist')):\n",
    "    print ('Begin LLM for App AI Assistant')\n",
    "    print ('---------------------------------------------------- \\n')\n",
    "    \n",
    "    # Acquire the context\n",
    "    response = retrieve(query, kb_app_assistant)\n",
    "    retrievalResults = response['retrievalResults']\n",
    "    contexts = get_contexts(retrievalResults)\n",
    "    \n",
    "    # Choose the prompt template\n",
    "    prompt_template_app = prompt_template_choice('App')\n",
    "    \n",
    "    # Format the Prompt with the prompt template\n",
    "    prompt_role_switching = prompt_choice (prompt_template_app, query, contexts, 'App')\n",
    "    \n",
    "    # Ingest data into the LLM (Modifications can be applied here)\n",
    "    response = data_ingestion (prompt_role_switching, prompt_template_app, contexts, query)\n",
    "    \n",
    "    # Call and print the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text_app = response_body.get('content')[0]['text']\n",
    "    print (response_text_app)\n",
    "    \n",
    "    print ('\\n ---------------------------------------------------- ')\n",
    "    print ('End of App AI Assistant')\n",
    "    print ('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx ')\n",
    "    \n",
    "\n",
    "if ((response_text_intent == 'Pain Psychologist') or (response_text_intent == 'AI Assistant for the App, Pain Psychologist')):\n",
    "    print ('Begin LLM for Pain Assistant')\n",
    "    print ('---------------------------------------------------- \\n')\n",
    "    \n",
    "    # Acquire the context\n",
    "    response = retrieve(query, kb_pain_assistant)\n",
    "    retrievalResults = response['retrievalResults']\n",
    "    contexts = get_contexts(retrievalResults)\n",
    "    \n",
    "    # Choose the prompt template\n",
    "    prompt_template_pain = prompt_template_choice('Pain')\n",
    "    \n",
    "    # Format the Prompt with the prompt template\n",
    "    prompt_role_switching = prompt_choice (prompt_template_pain, query, contexts, 'Pain')\n",
    "    \n",
    "    # Ingest data into the LLM (Modifications can be applied here)\n",
    "    response = data_ingestion (prompt_role_switching, prompt_template_pain, contexts, query)\n",
    "    \n",
    "    # Call and print the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text_pain = response_body.get('content')[0]['text']\n",
    "    print (response_text_pain)\n",
    "    \n",
    "    print ('\\n----------------------------------------------------')\n",
    "    print ('End of Pain AI Assistant')\n",
    "    print ('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx ')\n",
    "\n",
    "\n",
    "if (response_text_intent == 'AI Assistant for the App, Pain Psychologist'):\n",
    "    print ('Begin LLM for Pain and App Assistant')\n",
    "    print ('---------------------------------------------------- \\n')\n",
    "\n",
    "    # Acquire the context\n",
    "    \n",
    "    combined_query = response_text_pain + ' ' + response_text_app\n",
    "    \n",
    "    response = retrieve(combined_query, kb_aws_bedorck_s3)\n",
    "    retrievalResults = response['retrievalResults']\n",
    "    contexts = get_contexts(retrievalResults)\n",
    "\n",
    "    # Choose the prompt template\n",
    "    prompt_template_pain_and_app = prompt_template_pain + ' ' + prompt_template_app\n",
    "\n",
    "    # Format the Prompt with the prompt template - This combines both the templates\n",
    "    prompt_role_pain_and_app = prompt_choice (prompt_template_pain, query, contexts, 'Both', prompt_template_app)\n",
    "    \n",
    "    # Ingest data into the LLM (Modifications can be applied here)\n",
    "    response = data_ingestion (prompt_role_pain_and_app, prompt_template_pain_and_app, contexts, query)\n",
    "    \n",
    "    # Call and print the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text_pain_and_app = response_body.get('content')[0]['text']\n",
    "    print (response_text_pain_and_app)\n",
    "    \n",
    "    print ('\\n----------------------------------------------------')\n",
    "    print ('End of Pain and App AI Assistant')\n",
    "    print ('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1c847-cff8-4d45-9bbb-4559d3d6314b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
