{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b82e142-b2a5-4e2d-b44d-e7f07d2d98be",
   "metadata": {},
   "source": [
    "# This notebook is to replicate what we were able to achieve on the AWS console\n",
    "\n",
    "- Creating through bedrock-agent for more confirugation and control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a76e44b-5b65-411e-93d8-bd6ee5084a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running boto3 version: 1.35.34\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError, ClientError\n",
    "import os\n",
    "import random\n",
    "from retrying import retry\n",
    "import time\n",
    "from utility import *\n",
    "print('Running boto3 version:', boto3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671063e9-c053-4550-b89a-c5488133eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bedrock agent client\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name or 'ca-central-1'\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0}, region_name=region_name)\n",
    "bedrock_agent_client = boto3_session.client(\"bedrock-agent-runtime\", config=bedrock_config)\n",
    "\n",
    "# Define FM to be used for generations \n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\" \n",
    "model_arn = f'arn:aws:bedrock:{region_name}::foundation-model/{model_id}'\n",
    "\n",
    "# knowledge-base-AWS-bedrock-psychiatrist\n",
    "kb_id = '76UIT87ACB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d075138-c885-4fc1-b461-21c99efb386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the default knowledge base prompt\n",
    "\n",
    "path = '../machine-learning/4. Knowledge Base Template/'\n",
    "filename = 'RoleSwitching_V4_Oct2.md'\n",
    "\n",
    "with open(path+filename, 'r') as f:\n",
    "    default_prompt = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573061e-025f-4fd3-b959-6a85a7ce69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    " 'knowledgeBaseConfiguration': {\n",
    "            'generationConfiguration': {\n",
    "                'additionalModelRequestFields': {\n",
    "                    'string': {...}|[...]|123|123.4|'string'|True|None\n",
    "                },\n",
    "                'guardrailConfiguration': {\n",
    "                    'guardrailId': 'string',\n",
    "                    'guardrailVersion': 'string'\n",
    "                },\n",
    "                'inferenceConfig': {\n",
    "                    'textInferenceConfig': {\n",
    "                        'maxTokens': 123,\n",
    "                        'stopSequences': [\n",
    "                            'string',\n",
    "                        ],\n",
    "                        'temperature': ...,\n",
    "                        'topP': ...\n",
    "                    }\n",
    "                },\n",
    "                'promptTemplate': {\n",
    "                    'textPromptTemplate': 'string'\n",
    "                }\n",
    "            },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a61c60be-64df-4558-9eec-efa0c336890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# R and G is to `retrieve_and_generate`\n",
    "def retrieve_and_generate(query, kb_id, model_arn, max_results, prompt_template = default_prompt):\n",
    "    response = bedrock_agent_client.retrieve_and_generate(\n",
    "            input={\n",
    "                'text': query\n",
    "            },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "        'type': 'KNOWLEDGE_BASE',\n",
    "        'knowledgeBaseConfiguration': {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            'modelArn': model_arn,\n",
    "\n",
    "            # Retrieval Configuration\n",
    "            'retrievalConfiguration': {\n",
    "                'vectorSearchConfiguration': {\n",
    "                    'numberOfResults': max_results,\n",
    "                    'overrideSearchType': 'HYBRID'|'SEMANTIC'\n",
    "                    'overrideSearchType': 'HYBRID' or 'SEMANTIC'\n",
    "                    }\n",
    "                }, \n",
    "\n",
    "            # Generation Configuration\n",
    "            'generationConfiguration': {\n",
    "                    'promptTemplate': {\n",
    "                        'textPromptTemplate': prompt_template\n",
    "                    } ,\n",
    "                    'inferenceConfig': {\n",
    "                    'textInferenceConfig': {\n",
    "                        'maxTokens': 512,\n",
    "                        'temperature': 1.0,\n",
    "                        'topP': 1.0\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "\n",
    "            # Orchestration Confirugation\n",
    "            'orchestrationConfiguration': {\n",
    "                'queryTransformationConfiguration': {\n",
    "                    'type': 'QUERY_DECOMPOSITION'\n",
    "                    }\n",
    "                } \n",
    "            \n",
    "            } # Knowledge base configuration\n",
    "        }\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "# Printing Generation Results refers to the citations / references from the KB\n",
    "def print_generation_results(response, print_context = True):\n",
    "    generated_text = response['output']['text']\n",
    "    print('Generated FM response:\\n')\n",
    "    print(generated_text)\n",
    "    \n",
    "    if print_context is True:\n",
    "        ## print out the source attribution/citations from the original documents to see if the response generated belongs to the context.\n",
    "        citations = response[\"citations\"]\n",
    "        contexts = []\n",
    "        for citation in citations:\n",
    "            retrievedReferences = citation[\"retrievedReferences\"]\n",
    "            for reference in retrievedReferences:\n",
    "                contexts.append(reference[\"content\"][\"text\"])\n",
    "    \n",
    "        print('\\n\\n\\nRetrieved Context:\\n')\n",
    "        pprint.pp(contexts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5830446-6863-47ad-b8e7-f5719279d7c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mHow do I track my migraine?\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_and_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkb_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkb_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_arn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_arn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m print_generation_results(results)\n",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m, in \u001b[0;36mretrieve_and_generate\u001b[0;34m(query, kb_id, model_arn, max_results, prompt_template)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve_and_generate\u001b[39m(query, kb_id, model_arn, max_results, prompt_template \u001b[38;5;241m=\u001b[39m default_prompt):\n\u001b[1;32m      3\u001b[0m     response \u001b[38;5;241m=\u001b[39m bedrock_agent_client\u001b[38;5;241m.\u001b[39mretrieve_and_generate(\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      5\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: query\n\u001b[1;32m      6\u001b[0m             },\n\u001b[1;32m      7\u001b[0m         retrieveAndGenerateConfiguration\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKNOWLEDGE_BASE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledgeBaseConfiguration\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledgeBaseId\u001b[39m\u001b[38;5;124m'\u001b[39m: kb_id,\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelArn\u001b[39m\u001b[38;5;124m'\u001b[39m: model_arn,\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m             \u001b[38;5;66;03m# Retrieval Configuration\u001b[39;00m\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretrievalConfiguration\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     15\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectorSearchConfiguration\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     16\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumberOfResults\u001b[39m\u001b[38;5;124m'\u001b[39m: max_results,\n\u001b[0;32m---> 17\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverrideSearchType\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHYBRID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSEMANTIC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     18\u001b[0m                     }\n\u001b[1;32m     19\u001b[0m                 }, \n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m             \u001b[38;5;66;03m# Generation Configuration\u001b[39;00m\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerationConfiguration\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     23\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpromptTemplate\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     24\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtextPromptTemplate\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt_template\n\u001b[1;32m     25\u001b[0m                     } ,\n\u001b[1;32m     26\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minferenceConfig\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     27\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtextInferenceConfig\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     28\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxTokens\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     29\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m     30\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopP\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     31\u001b[0m                         }\n\u001b[1;32m     32\u001b[0m                     }\n\u001b[1;32m     33\u001b[0m                 },\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m             \u001b[38;5;66;03m# Orchestration Confirugation\u001b[39;00m\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morchestrationConfiguration\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     37\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueryTransformationConfiguration\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     38\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQUERY_DECOMPOSITION\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     39\u001b[0m                     }\n\u001b[1;32m     40\u001b[0m                 } \n\u001b[1;32m     41\u001b[0m             \n\u001b[1;32m     42\u001b[0m             } \u001b[38;5;66;03m# Knowledge base configuration\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         }\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "query = \"\"\"How do I track my migraine?\"\"\"\n",
    "\n",
    "results = retrieve_and_generate(query = query, kb_id = kb_id, model_arn = model_arn, max_results = 3)\n",
    "\n",
    "print_generation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac33a5-11d3-4dd3-a689-6757e49534d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4f91f-8826-4ad5-8a03-f64aa49d9650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
