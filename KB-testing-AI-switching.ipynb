{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d57f80-9d27-4dbc-8676-df032d19be5a",
   "metadata": {},
   "source": [
    "# Switching Assistant\n",
    "- Intent classification and Service Routing\n",
    "- The LLM analyzes this combination and classifies the input into one or combination of three main intents: AppAssistant, PainAssistant, or PersonalAssistant.\n",
    "- Creating through bedrock-agent for more confirugation and control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c2331d-b7d1-44e9-bd96-e19b7602de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running boto3 version: 1.35.34\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError, ClientError\n",
    "import os\n",
    "import random\n",
    "from retrying import retry\n",
    "import time\n",
    "from utility import *\n",
    "print('Running boto3 version:', boto3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e9f01-aada-46eb-9667-f8323098a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock Agent runtime\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "session = boto3.session.Session()\n",
    "region = 'ca-central-1'\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\", config=bedrock_config, region_name = region)\n",
    "\n",
    "# KB ID\n",
    "kb_id = 'V2W0LT3GZP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9544e97-e1f6-482f-8614-ffd7cf401000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, kbId, numberOfResults=5):\n",
    "    return bedrock_agent_client.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\", # optional\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['content']['text'])\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a428ae-3dce-4392-844f-738de7f9501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the default knowledge base prompt\n",
    "\n",
    "path = '../machine-learning/4. Knowledge Base Template/'\n",
    "filename = 'Switching_Assistant_V1_Oct17.md'\n",
    "\n",
    "with open(path+filename, 'r') as f:\n",
    "    prompt_template = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691291e8-23de-40a3-822b-c06693f4903b",
   "metadata": {},
   "source": [
    "Evaluating role switching on Potential Questions 2 (which is supposed to be only for app assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b4b9b-8e92-49fa-925a-4a436b1f7321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the questions that we want to ask\n",
    "\n",
    "path = '../machine-learning/6. Test Cases/App Assistant/'\n",
    "filename = 'Potential-Questions2.md'\n",
    "\n",
    "with open(path+filename, 'r') as f:\n",
    "    questions = f.read()\n",
    "\n",
    "queries = questions.split('\\n')\n",
    "\n",
    "\n",
    "# Going through the queries to send to LLM\n",
    "\n",
    "for query in queries:\n",
    "    print ('---------------------------------------------------- \\n')\n",
    "\n",
    "    # Acquire the context\n",
    "    response = retrieve(query, kb_id)\n",
    "    retrievalResults = response['retrievalResults']\n",
    "    contexts = get_contexts(retrievalResults)\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = f\"\"\"\n",
    "    Human: Use the following <context> to determine if the intent of <query> is classified as AI App assistant or as the \n",
    "    Pain assistant as decribed in <prompt_template>\n",
    "    \n",
    "    <prompt_template>\n",
    "    {prompt_template}\n",
    "    </prompt_template>\n",
    "    \n",
    "    <context>\n",
    "    {contexts}\n",
    "    </context>\n",
    "    \n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    Only respond with the title name of the assistant chosen.\n",
    "    Do not respond if the prompt is not related to <contexts>.\n",
    "    \n",
    "    Assistant:\"\"\"\n",
    "\n",
    "    # Prepare the information to be invoked into the model\n",
    "    messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt.format(prompt_template, contexts, query)}]}]\n",
    "    sonnet_payload = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1\n",
    "            }  )\n",
    "    modelId = 'anthropic.claude-3-sonnet-20240229-v1:0' \n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    response = bedrock_client.invoke_model(body=sonnet_payload, \n",
    "                                           modelId=modelId, \n",
    "                                           accept=accept, \n",
    "                                           contentType=contentType)\n",
    "\n",
    "    # Call and print the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text = response_body.get('content')[0]['text']\n",
    "    # pp.pprint (query)\n",
    "    # pp.pprint(response_text)\n",
    "    print (query)\n",
    "    print (response_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a6ce1-fa2a-4f1d-9927-45e107a9a3dc",
   "metadata": {},
   "source": [
    "--- \n",
    "# Test the role switching from app assistant to pain pscyhology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc807000-703d-42b8-b02a-c1bafe79b8d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the questions that we want to ask\n",
    "\n",
    "path = '../machine-learning/6. Test Cases/'\n",
    "filename = 'Role-Switching2.md'\n",
    "\n",
    "with open(path+filename, 'r') as f:\n",
    "    questions = f.read()\n",
    "\n",
    "queries = questions.split('\\n')\n",
    "\n",
    "\n",
    "# Going through the queries to send to LLM\n",
    "\n",
    "for query in queries:\n",
    "    print ('---------------------------------------------------- \\n')\n",
    "\n",
    "    # Acquire the context\n",
    "    response = retrieve(query, kb_id)\n",
    "    retrievalResults = response['retrievalResults']\n",
    "    contexts = get_contexts(retrievalResults)\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = f\"\"\"\n",
    "    Human: Use the following <context> to determine if the intent of <query> is classified as AI App assistant or as the \n",
    "    Pain assistant as decribed in <prompt_template>. \n",
    "    \n",
    "    <prompt_template>\n",
    "    {prompt_template}\n",
    "    </prompt_template>\n",
    "    \n",
    "    <context>\n",
    "    {contexts}\n",
    "    </context>\n",
    "    \n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    Only respond with the title name of the assistant(s) chosen. \n",
    "    Do not respond if the prompt is not related to <contexts>.\n",
    "    \n",
    "    Assistant:\"\"\"\n",
    "\n",
    "    # Prepare the information to be invoked into the model\n",
    "    messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt.format(prompt_template, contexts, query)}]}]\n",
    "    sonnet_payload = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1\n",
    "            }  )\n",
    "    modelId = 'anthropic.claude-3-sonnet-20240229-v1:0' \n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    response = bedrock_client.invoke_model(body=sonnet_payload, \n",
    "                                           modelId=modelId, \n",
    "                                           accept=accept, \n",
    "                                           contentType=contentType)\n",
    "\n",
    "    # Call and print the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text = response_body.get('content')[0]['text']\n",
    "    # pp.pprint (query)\n",
    "    # pp.pprint(response_text)\n",
    "    print (query)\n",
    "    print (response_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aef34e-06b6-4ae3-86c4-a86efc414bfd",
   "metadata": {},
   "source": [
    "--- \n",
    "# Role switching extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84ce3ec7-700b-404a-a55d-81731790609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock Agent runtime\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "session = boto3.session.Session()\n",
    "region = 'ca-central-1'\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\", config=bedrock_config, region_name = region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8d853e8-7785-4c6e-b5f7-b2f0c05e1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, kbId, numberOfResults=5):\n",
    "    return bedrock_agent_client.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\", # optional\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['content']['text'])\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c015d221-6812-458b-a6fc-8233e06039aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_choice (prompt_template, query, contexts, choice):\n",
    "\n",
    "        if (choice == 'Intent'):\n",
    "            prompt = f\"\"\"\n",
    "            Human: Use the following <context> to determine if the intent of <query> is classified as AI App assistant or as the \n",
    "            Pain assistant as decribed in <prompt_template>. \n",
    "\n",
    "            If the intent is classified as AI App assistant then respond with 'AI Assistant for the App', \n",
    "            if the intent is classified as the Pain assistant then respond with 'Pain Psychologist',\n",
    "            if the intent is classifed as both the AI App assistant and Pain assistant then respond with 'AI Assistant for the App, Pain Psychologist'\n",
    "            \n",
    "            <prompt_template>\n",
    "            {prompt_template}\n",
    "            </prompt_template>\n",
    "            \n",
    "            <context>\n",
    "            {contexts}\n",
    "            </context>\n",
    "            \n",
    "            <query>\n",
    "            {query}\n",
    "            </query>\n",
    "        \n",
    "            Only respond with the title name of the assistant(s) chosen. \n",
    "            Do not respond if the prompt is not related to <contexts>.\n",
    "            \n",
    "            Assistant:\"\"\"\n",
    "            \n",
    "        elif (choice == 'Pain'):\n",
    "            prompt = f\"\"\"\n",
    "            Human: Use the following <context> to answer the <query> according to your role in <prompt_template>. \n",
    "            <prompt_template>\n",
    "            {prompt_template}\n",
    "            </prompt_template>\n",
    "            \n",
    "            <context>\n",
    "            {contexts}\n",
    "            </context>\n",
    "            \n",
    "            <query>\n",
    "            {query}\n",
    "            </query>\n",
    "            \n",
    "            Do not respond if the prompt is not related to pain Psychology.\n",
    "            Do not respond if the prompt is not related to <contexts>.\n",
    "            Do not respond if the prompt is related to usage of the app.\n",
    "            \n",
    "            Assistant:\"\"\"\n",
    "\n",
    "\n",
    "        elif (choice == 'App'):\n",
    "            prompt = f\"\"\"\n",
    "            Human: Use the following <context> to answer the <query> according to your role in <prompt_template>. \n",
    "            <prompt_template>\n",
    "            {prompt_template}\n",
    "            </prompt_template>\n",
    "            \n",
    "            <context>\n",
    "            {contexts}\n",
    "            </context>\n",
    "            \n",
    "            <query>\n",
    "            {query}\n",
    "            </query>\n",
    "            \n",
    "            Do not respond if the prompt is not related to the app.\n",
    "            \n",
    "            Assistant:\"\"\"\n",
    "            \n",
    "\n",
    "        return (prompt)\n",
    "\n",
    "\n",
    "def prompt_template_choice(choice):\n",
    "    # Assigning the default knowledge base prompt\n",
    "    path = '../machine-learning/4. Knowledge Base Template/'\n",
    "\n",
    "    if (choice == 'Intent'):\n",
    "        filename = 'Switching_Assistant_V1_Oct17.md'\n",
    "\n",
    "    elif (choice == 'Pain'):\n",
    "        filename = 'Pain_Assistant_V1_Oct15.md'\n",
    "            \n",
    "    elif (choice == 'App'):\n",
    "        filename = 'App_Assistant_V1_Oct10.md'\n",
    "        \n",
    "    with open(path+filename, 'r') as f:\n",
    "        prompt_template = f.read()\n",
    "            \n",
    "    return (prompt_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d77221ca-1cd8-4554-93d5-b670c228466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_ingestion (prompt, prompt_template, contexts, query, temp = 1):\n",
    "\n",
    "    # Prepare the information to be invoked into the model\n",
    "    messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt.format(prompt_template, contexts, query)}]}]\n",
    "    sonnet_payload = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"messages\": messages,\n",
    "    \"temperature\": temp,\n",
    "    \"top_p\": 1\n",
    "        }  )\n",
    "    modelId = 'anthropic.claude-3-sonnet-20240229-v1:0' \n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    response = bedrock_client.invoke_model(body=sonnet_payload, \n",
    "                                       modelId=modelId, \n",
    "                                       accept=accept, \n",
    "                                       contentType=contentType)\n",
    "    \n",
    "    return (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e779fed1-520f-4c75-84b7-32cb31ec1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge base ID\n",
    "\n",
    "kb_aws_bedorck_s3 = '76UIT87ACB'\n",
    "kb_app_assistant = 'V2W0LT3GZP'\n",
    "kb_pain_assistant = 'KESDTCXEJE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8e74a18-974a-4369-bd90-124ec213bb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the questions that we want to ask\n",
    "\n",
    "path = '../machine-learning/6. Test Cases/'\n",
    "filename = 'Role-Switching2.md'\n",
    "\n",
    "with open(path+filename, 'r') as f:\n",
    "    questions = f.read()\n",
    "\n",
    "queries = questions.split('\\n')\n",
    "query = queries [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d30a6fa3-2c28-4004-81f2-bc0cd3fcd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \n",
      "Begin LLM for Intent Classification\n",
      "---------------------------------------------------- \n",
      "\n",
      "How do I update my pain condition in the app? How does stress or anxiety affect my pain levels?\n",
      "I cannot provide advice about changing medications or dosages, as that would require medical consultation. However, I can explain how the Manage My Pain app allows you to record your pain condition symptoms and track potential triggers like stress or anxiety.\n",
      "\n",
      "The app lets you log your daily pain levels, symptoms, activities, and treatments. You can review these entries over time to identify patterns or factors that may worsen or improve your condition. For example, if you notice stress or anxiety often precedes increased pain levels, you can discuss this with your doctor.\n",
      "\n",
      "The app also has journaling features where you can document your experiences, emotions, and reflections related to living with chronic pain. This documentation can help facilitate more productive conversations with your healthcare providers.\n",
      "\n",
      "Please let me know if you need any other assistance with navigating or using the Manage My Pain app features. I'm happy to provide guidance, but cannot recommend changes to your treatment plan.\n",
      "\n",
      "---------------------------------------------------- \n",
      "End of intent classification\n",
      "---------------------------------------------------- \n",
      "Begin LLM for App AI Assistant\n",
      "---------------------------------------------------- \n",
      "\n",
      "I can provide instructions on how to update pain conditions in the Manage My Pain app, but I cannot advise on how stress or anxiety affects your personal pain levels, as that would be providing medical advice.\n",
      "\n",
      "To update your pain conditions in the app:\n",
      "\n",
      "1. Tap on the \"Profile\" section\n",
      "2. Select \"Pain Conditions\"\n",
      "3. Tap the \"Edit\" button next to the condition you want to update\n",
      "4. Make your desired changes and tap \"Save\"\n",
      "\n",
      "The app allows you to customize conditions, locations, symptoms, triggers, and treatments specific to your situation. This can help track how different activities impact your pain levels over time.\n",
      "\n",
      "Let me know if you need any clarification on updating pain conditions in the app.\n",
      "\n",
      " ---------------------------------------------------- \n",
      "End of App AI Assistant\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \n",
      "Begin LLM for Pain Assistant\n",
      "---------------------------------------------------- \n",
      "\n",
      "As a pain psychologist, I can offer some guidance on how stress and anxiety may impact pain levels:\n",
      "\n",
      "Stress and anxiety can amplify pain perception and make pain feel more intense. When we experience chronic stress, it causes muscle tension, increased inflammation, and disrupted sleep - all of which can contribute to higher pain sensitivity. Anxiety about pain can also lead to fear-avoidance behaviors that reduce activity levels and worsen functioning over time.\n",
      "\n",
      "To manage the impacts of stress and anxiety on pain:\n",
      "\n",
      "- Practice relaxation techniques like deep breathing, meditation or progressive muscle relaxation to reduce muscle tension.\n",
      "- Challenge catastrophic thinking patterns about pain through cognitive-behavioral strategies.\n",
      "- Engage in regular exercise and activity pacing to improve functioning.\n",
      "- Build your stress management skills through techniques like mindfulness and stress resilience training.\n",
      "\n",
      "Reducing stress and anxiety through psychological approaches can be an important part of a comprehensive pain management plan. Let me know if you need any other specific guidance on coping with the psychological aspects of chronic pain.\n",
      "\n",
      "----------------------------------------------------\n",
      "End of Pain AI Assistant\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \n",
      "Do something with both llms and then combined it with another LLM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Main body of the analysis\n",
    "\n",
    "print ('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx ')\n",
    "print ('Begin LLM for Intent Classification')\n",
    "print ('---------------------------------------------------- \\n')\n",
    "\n",
    "# Acquire the context\n",
    "response = retrieve(query, kb_aws_bedorck_s3)\n",
    "retrievalResults = response['retrievalResults']\n",
    "contexts = get_contexts(retrievalResults)\n",
    "\n",
    "# Choose the prompt template\n",
    "prompt_template = prompt_template_choice('Intent')\n",
    "\n",
    "# Format the Prompt with the prompt template\n",
    "prompt_role_switching = prompt_choice (prompt_template, query, contexts, 'Intent')\n",
    "\n",
    "# Ingest data into the LLM (Modifications can be applied here)\n",
    "response = data_ingestion (prompt_role_switching, prompt_template, contexts, query, 0)\n",
    "\n",
    "# Call and print the response\n",
    "response_body = json.loads(response.get('body').read())\n",
    "response_text_intent = response_body.get('content')[0]['text']\n",
    "print (query)\n",
    "print (response_text)\n",
    "\n",
    "print ('\\n---------------------------------------------------- ')\n",
    "print ('End of intent classification')\n",
    "print ('---------------------------------------------------- ')\n",
    "\n",
    "if ((response_text_intent == 'AI Assistant for the App') or (response_text_intent == 'AI Assistant for the App, Pain Psychologist')):\n",
    "    print ('Begin LLM for App AI Assistant')\n",
    "    print ('---------------------------------------------------- \\n')\n",
    "    \n",
    "    # Acquire the context\n",
    "    response = retrieve(query, kb_app_assistant)\n",
    "    retrievalResults = response['retrievalResults']\n",
    "    contexts = get_contexts(retrievalResults)\n",
    "    \n",
    "    # Choose the prompt template\n",
    "    prompt_template = prompt_template_choice('App')\n",
    "    \n",
    "    # Format the Prompt with the prompt template\n",
    "    prompt_role_switching = prompt_choice (prompt_template, query, contexts, 'App')\n",
    "    \n",
    "    # Ingest data into the LLM (Modifications can be applied here)\n",
    "    response = data_ingestion (prompt_role_switching, prompt_template, contexts, query)\n",
    "    \n",
    "    # Call and print the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text_app = response_body.get('content')[0]['text']\n",
    "    print (response_text_app)\n",
    "    \n",
    "    print ('\\n ---------------------------------------------------- ')\n",
    "    print ('End of App AI Assistant')\n",
    "    print ('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx ')\n",
    "    \n",
    "\n",
    "if ((response_text_intent == 'Pain Psychologist') or (response_text_intent == 'AI Assistant for the App, Pain Psychologist')):\n",
    "    print ('Begin LLM for Pain Assistant')\n",
    "    print ('---------------------------------------------------- \\n')\n",
    "    \n",
    "    # Acquire the context\n",
    "    response = retrieve(query, kb_pain_assistant)\n",
    "    retrievalResults = response['retrievalResults']\n",
    "    contexts = get_contexts(retrievalResults)\n",
    "    \n",
    "    # Choose the prompt template\n",
    "    prompt_template = prompt_template_choice('Pain')\n",
    "    \n",
    "    # Format the Prompt with the prompt template\n",
    "    prompt_role_switching = prompt_choice (prompt_template, query, contexts, 'Pain')\n",
    "    \n",
    "    # Ingest data into the LLM (Modifications can be applied here)\n",
    "    response = data_ingestion (prompt_role_switching, prompt_template, contexts, query)\n",
    "    \n",
    "    # Call and print the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text_pain = response_body.get('content')[0]['text']\n",
    "    print (response_text_pain)\n",
    "    \n",
    "    print ('\\n----------------------------------------------------')\n",
    "    print ('End of Pain AI Assistant')\n",
    "    print ('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx ')\n",
    "\n",
    "\n",
    "if (response_text_intent == 'AI Assistant for the App, Pain Psychologist'):\n",
    "    print (\"Do something with both llms and then combined it with another LLM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204f4f8-a33f-402e-a951-8b6f9647c97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7ff5c-eea7-430a-bde5-ad75c894f98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e213ee22-3b0a-435a-bf24-c9d4775f75ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae80f83-9168-46b5-a463-405286192287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
